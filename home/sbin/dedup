#!/usr/bin/env python
# encoding: utf-8
from __future__ import unicode_literals
import base64, hashlib, itertools, json, locale, os, re, sqlite3, sys
sys.path = ["."] + sys.path
import config

def shell_escape(s):
    return "'{0}'".format(s.replace("'", "'\\''"))

def hash_file(filename, algorithm, blocksize=65536):
    h = algorithm()
    with open(filename, "rb") as f:
        for block in iter(lambda: f.read(blocksize), b""):
            h.update(block)
    return h

def filehash(db, filename, cached_only=False):
    r = tuple(db.execute("SELECT hash FROM hashes WHERE path = ?", [filename]))
    if r:
        return bytes(r[0][0])
    if cached_only:
        return None
    if os.path.islink(filename):
        h = None
    else:
        h = hash_file(filename, algorithm=HASH).digest()
    with db:
        db.execute("INSERT INTO hashes (path, hash) VALUES (?, ?)",
                   [filename, h])
    return h

def listdir(db, dirname):
    r = tuple(db.execute("SELECT children FROM dirs WHERE path = ?",
                         [dirname]))
    if r:
        s = r[0][0]
        if s is None:
            return None
        else:
            if s == "":
                return []
            return sorted(s.split("\0"))
    if os.path.islink(dirname) or not os.path.isdir(dirname):
        cs = None
    else:
        cs = sorted(os.listdir(dirname))
    with db:
        db.execute("INSERT INTO dirs (path, children) VALUES (?, ?)",
                   [dirname, None if cs is None else "\0".join(cs)])
    return cs

def multidict_add(d, k, v):
    if k in d:
        d[k].append(v)
    else:
        d[k] = [v]

def render_hash(h):
    return base64.b64encode(h).decode("latin-1").rstrip("=")

def is_excluded(path):
    for excl in EXCLUDES:
        if re.search(excl, path):
            return True
    return False

def capture(d, v, k):
    h = HASH(k).digest()
    multidict_add(d, h, v)
    return h

def proc_dir(db, d, path):
    children = listdir(db, path)
    if children is None: # file or link
        return capture(d, path, b"f" + os.path.basename(path).encode("utf8"))
    hashes = [b"d"]
    for child in children:
        childpath = os.path.join(path, child)
        hashes.append(proc_dir(db, d, childpath))
    return capture(d, path, b"".join(hashes))

def check_dir(db, d, path, candidates, cached_only=False):
    children = listdir(db, path)
    if children is None: # file or link
        if path in candidates and not is_excluded(path):
            h = filehash(db, path, cached_only=cached_only)
        else:
            h = None
        if h is None:
            return None
        return capture(d, path,
                       b"f" + h + os.path.basename(path).encode("utf8"))
    hashes = [b"d"]
    for child in children:
        childpath = os.path.join(path, child)
        h = check_dir(db, d, childpath, candidates, cached_only=cached_only)
        if None in (h, hashes):
            hashes = None
        else:
            hashes.append(h)
    if hashes is None:
        return None
    return capture(d, path, b"".join(hashes))

def compute_pref(prefs, path):
    pref = prefs.get(path, None)
    if pref is not None:
        return pref
    parent = os.path.dirname(path)
    if parent == path:
        return 0
    return compute_pref(prefs, parent)

PREFERREDENCODING = locale.getpreferredencoding()
def as_str(s):
    if (hasattr("", "decode") and hasattr("", "encode") and
        isinstance(s, bytes)):
        return s.decode(PREFERREDENCODING)
    return s

def dump_hashes(db, root, path):
    children = listdir(db, path)
    if children is None: # file or link
        h = filehash(db, path)
        if h is None: # link
            h = "{0}&".format(render_hash(HASH(os.readlink("../sy_data"))
                                          .digest()))
        else: # file
            h = "{0} ".format(render_hash(h))
        sys.stdout.write("{0} {1}\n".format(h, os.path.relpath(path, root)))
        return
    for child in children:
        childpath = os.path.join(path, child)
        dump_hashes(db, root, childpath)

def find_dupes(db):
    db.executescript("""
    CREATE TABLE IF NOT EXISTS dirs (path TEXT UNIQUE, children TEXT);
    CREATE TABLE IF NOT EXISTS hashes (path TEXT UNIQUE, hash BLOB);
    """)

    sys.stderr.write("# Reading directory structure...\n")
    sys.stderr.flush()
    d = {}
    proc_dir(db, d, root)

    sys.stderr.write("# Finding potential duplicates...\n")
    sys.stderr.flush()
    if not CANDIDATE_ALL:
        d = dict((h, ps) for h, ps in d.items() if len(ps) > 1)
    candidates = sorted(set(itertools.chain(*(v for v in d.values()))))

    sys.stderr.write("# Checking contents of files...\n")
    sys.stderr.flush()
    d = {}
    check_dir(db, d, root, candidates, cached_only=CACHED_ONLY)

    sys.stderr.write("# Finding duplicates...\n")
    sys.stderr.flush()
    d = dict((h, tuple(sorted(ps))) for h, ps in d.items() if len(ps) > 1)

    # remove redundant ones for children if parents are already duplicates
    rd = {}
    for h, ps in d.items():
        for p in ps:
            rd[p] = h
    to_be_removed = []
    for h, ps in d.items():
        hp0 = None
        for p in ps:
            hp = rd.get(os.path.dirname(p), None)
            if hp is None:
                break
            if hp0 is None:
                hp0 = hp
            elif hp0 != hp:
                break
        else:
            to_be_removed.append(h)
    for h in to_be_removed:
        del d[h]

    with open(out_fn, "wt") as f:
        json.dump(dict((base64.b16encode(h).decode("latin-1"), ps)
                       for h, ps in d.items()), f)

    print("""#!/bin/bash
. rem.sh
""")
    sys.stdout.write("cd {0}\n\n".format(shell_escape(root)))
    sys.stdout.flush()
    for h, ps in sorted(d.items(), key=lambda x: x[1]):
        if directory_only and listdir(db, ps[0]) is None:
            continue
        ps = [os.path.relpath(p, root) for p in ps]
        prefs = [compute_pref(PREFS, p) for p in ps]
        pprefs = sorted(zip(ps, prefs), key=lambda x: x[1])
        if pprefs[-1][1] == pprefs[-2][1]:
            sys.stdout.write("# warning: there is no winner for:\n")
#                sys.stdout.flush()
            keep_all = True
            p0 = lambda priority: "# {0}".format(priority)
        else:
            keep_all = False
            p0 = lambda _: shell_escape(pprefs[-1][0])
        for i, (p, priority) in enumerate(pprefs):
            keep = keep_all or i == len(pprefs) - 1
            sys.stdout.write("{0}X {1} {2}\n"
                             .format("#" if keep else "",
                                     shell_escape(p),
                                     p0(priority)))
        sys.stdout.write("\n")
        sys.stdout.flush()

ENCODING = "utf-8"
HASH = hashlib.sha1
PREFS = getattr(config, "prefs", {})
EXCLUDES = getattr(config, "excludes", [])

root = as_str(sys.argv[1])
db_fn = "dedup.sqlite"
out_fn = "dedup.json"
directory_only = True

root = os.path.realpath(root)
EXCLUDES = [os.path.join("^" + root, s) for s in EXCLUDES]

CACHED_ONLY = True
CANDIDATE_ALL = True

db = sqlite3.connect(db_fn)
try:
    #find_dupes(db)
    dump_hashes(db, root, root)
finally:
    db.close()
