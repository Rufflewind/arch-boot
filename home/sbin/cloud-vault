#!/usr/bin/env python3
#
# The 'backend' is an executable program that supports:
#
#     <backend> download <remote-path> <local-path>
#     <backend> rm <remote-path>
#     <backend> upload <local-path> <remote-path>

import argparse, base64, contextlib, datetime, hashlib, json, os
import re, shlex, sqlite3, stat, subprocess, sys, urllib.parse
assert sys.hexversion >= 0x03050000 # Python 3.5 is required
sys.path.insert(0, os.path.expanduser("~/stuff/_urandom"))
import utils

def display_digest(hashed):
    digest = hashed.digest()[:20]
    return base64.urlsafe_b64encode(digest).decode("ascii").rstrip("=")

def display_mode(mode):
    return "755" if mode & stat.S_IXUSR else "644"

def parse_mode(mode):
    if mode not in ["644","755"]:
        raise ValueError("unsupported mode: {}".format(mode))
    return int(mode, base=8) & 0o777

def display_time(timestamp_ns):
    return (
        re.sub("[:-]", "", datetime.datetime.utcfromtimestamp(
            timestamp_ns // 1000000000
        ).isoformat()) +
        ".{:09}Z".format(timestamp_ns % 1000000000))

def parse_time(isotime):
    t, ns = isotime.split(".")
    t = (datetime.datetime.strptime(t, "%Y%m%dT%H%M%S") -
         datetime.datetime(1970, 1, 1)) // datetime.timedelta(seconds=1)
    ns = int(ns.rstrip("Z"))
    return t * 1000000000 + ns

def generate_remote_id(seed, hash):
    return display_digest(hashlib.sha512((seed + hash).encode("utf-8")))

def is_vault_link(file):
    return (os.path.islink(file) and
            os.readlink(file).startswith("vault://"))

def get_file_hash(file):
    return "sha512:" + display_digest(utils.hash_file(hashlib.sha512, file))

def warn(s):
    sys.stderr.write(s)
    sys.stderr.flush()

def get_info_from_vault_link(seed, file):
    target = os.readlink(file)
    hash, qs = re.match(r"vault://([^?]+)\?(.*)", target).groups()
    attrs = dict(urllib.parse.parse_qsl(qs))
    return {
        "hash": hash,
        "remote_id": generate_remote_id(seed, hash),
        "mode": attrs["mode"],
        "mtime": attrs["mtime"],
    }

def get_info(seed, file, ignore_mode):
    st = os.lstat(file)
    if not stat.S_ISREG(st.st_mode):
        raise Exception("not a file: {!r}".format(file))
    hash = get_file_hash(file)
    return {
        "hash": hash,
        "remote_id": generate_remote_id(seed, hash),
        "mode": display_mode(0o644 if ignore_mode else st.st_mode),
        "mtime": display_time(st.st_mtime_ns),
    }

def info(files, ignore_mode, seed, transfer, db, **kwargs):
    for file in files:
        if not os.path.lexists(file):
            raise Exception("does not exist: {}".format(file))
        if os.path.islink(file):
            info = get_info_from_vault_link(seed, file)
        else:
            info = get_info(seed, file, ignore_mode)
        sys.stdout.write(json.dumps(info, **utils.JSON_PRETTY) + "\n")

def get(files, seed, transfer, db, **kwargs):
    for file in files:
        if not os.path.lexists(file):
            raise Exception("does not exist: {}".format(file))
        if not os.path.islink(file):
            warn("skipping (already got): {}\n".format(file))
            continue
        info = get_info_from_vault_link(seed, file)
        mode = parse_mode(info["mode"])
        mtime = parse_time(info["mtime"])
        tmp = file + ".download.tmp" # keep name consistent to allow resumption
        try:
            subprocess.check_call(transfer +
                                  ["download", "--", info["remote_id"], tmp])
        except:
            try:
                if os.lstat(tmp).st_size == 0:
                    os.remove(tmp)
            except OSError:
                pass
            raise
        tmp_hash = get_file_hash(tmp)
        if tmp_hash != info["hash"]:
            raise Exception("hash of downloaded file ({}) does not match"
                            .format(tmp_hash))
        os.utime(tmp, ns=(os.lstat(tmp).st_atime_ns, mtime))
        os.chmod(tmp, mode)
        os.rename(file, file + ".link")
        os.rename(tmp, file)

def put(files, delete, ignore_mode, seed, transfer, db, **kwargs):
    for file in files:
        if is_vault_link(file):
            warn("skipping (already put): {}\n".format(file))
            continue
        info = get_info(seed, file, ignore_mode)
        if tuple(db.execute("SELECT 1 FROM hashes WHERE hash = ?",
                            [info["hash"]])):
            warn("skipping upload (already indexed): {}\n"
                 .format(file))
        else:
            remote_id = generate_remote_id(seed, info["hash"])
            subprocess.check_call(transfer + ["upload", "--", file,
                                              info["remote_id"]])
            with db:
                db.execute("BEGIN")
                db.execute("INSERT INTO hashes (hash) VALUES (?)",
                           [info["hash"]])
        target = "vault://{}?{}".format(info["hash"], urllib.parse.urlencode([
            ("mode", info["mode"]),
            ("mtime", info["mtime"]),
        ]))
        bak_file = file + ".bak"
        with open(bak_file, "x"):
            pass
        os.rename(file, bak_file)
        os.symlink(target, file)
        if delete:
            os.remove(bak_file)

def gc(**kwargs):
    raise None

def main():
    p = argparse.ArgumentParser()
    p.add_argument("--index", required=True,
                   help="SQLite3 database to store the known hashes")
    p.add_argument("--seed", required=True,
                   help="seed for generating remote IDs")
    p.add_argument("--transfer", required=True, type=shlex.split,
                   help="cloud-transfer command")
    p.add_argument("--ignore-mode", action="store_true",
                   help="Treat the file mode as 644")
    sp = p.add_subparsers()

    spp = sp.add_parser("gc")
    spp.set_defaults(func=gc)
    spp.add_argument("--dry-run", "-n", action="store_true")

    spp = sp.add_parser("info", help="Retrieve information about file/link")
    spp.set_defaults(func=info)
    spp.add_argument("files", nargs="+", type=os.path.abspath,
                     help="filename of the local file")

    spp = sp.add_parser("get",
                        help=("Replace a vault link with the actual file. "
                              "The link is backed up to *.link"))
    spp.set_defaults(func=get)
    spp.add_argument("files", nargs="+", type=os.path.abspath,
                     help="path to the local metadata files")

    spp = sp.add_parser("put",
                        help=("Upload and replace the file with a vault link. "
                              "The original file is backed up to *.bak"))
    spp.set_defaults(func=put)
    spp.add_argument("-D", "--delete", action="store_true",
                     help="Don't make a backup of the file.")
    spp.add_argument("files", nargs="+", type=os.path.abspath,
                     help="filename of the local file")

    kwargs = vars(p.parse_args())
    func = kwargs.pop("func", None)
    if not func:
        p.print_usage()
        return 2

    os.makedirs(os.path.realpath(os.path.dirname(kwargs["index"])),
                exist_ok=True)
    with contextlib.closing(sqlite3.connect(kwargs["index"])) as db:
        migrations = [
            [
                """
                CREATE TABLE hashes
                ( hash TEXT UNIQUE
                )
                """,
                """
                CREATE TABLE aliases
                ( alias TEXT UNIQUE
                , hash TEXT
                , FOREIGN KEY(hash) REFERENCES hashes(hash)
                )
                """,
            ]
        ]
        db.execute("PRAGMA auto_vacuum = FULL")
        with db:
            db.execute("BEGIN")
            version = max(0, tuple(db.execute("PRAGMA user_version"))[0][0])
            for migration in migrations[version:]:
                for stmt in migration:
                    db.execute(stmt)
            db.execute("PRAGMA user_version = {}".format(len(migrations)))
        return func(db=db,
                    **kwargs) or 0

if __name__ == "__main__":
    sys.exit(main())
