#!/usr/bin/env python3
import argparse, hashlib, logging, os, random, re, shlex, subprocess, sys, time

#@snip/try_remove[
#@requires: mod:os
#@origin: try_remove
def try_remove(path):
    try:
        os.remove(path)
    except OSError:
        return False
    return True
#@]

#@snip/hash_file[
#@origin: hash_file
def hash_file(hasher, file, block_size=(1 << 20)):
    if isinstance(file, str):
        with open(file, "rb") as f:
            return hash_file(hasher, f, block_size=block_size)
    h = hasher()
    for block in iter(lambda: file.read(block_size), b""):
        h.update(block)
    return h
#@]

def run(cmd, *args, **kwargs):
    logging.debug("$ " + " ".join(cmd))
    return subprocess.run(cmd, *args, **kwargs)

def backoff(timeout):
    def wrapper(f):
        max_delay = 1.0
        remaining = timeout
        while True:
            try:
                return f()
            except Exception as e:
                err = e
            delay = random.uniform(0.0, max_delay)
            if remaining < delay:
                raise err
            time.sleep(delay)
            remaining -= delay
            if max_delay < 256.0:
                max_delay *= 2.0
    return wrapper

def _md5sum(filename):
    return hash_file(hashlib.md5, filename).hexdigest()

def md5sum(remote_fn, remote):
    r = run(["rclone", "md5sum", remote + remote_fn],
            check=True,
            stdin=subprocess.DEVNULL,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            universal_newlines=True)
    h = r.stdout[:32]
    if not re.match('[0-9a-f]{32}$', h):
        raise ValueError("did not receive a valid md5 hash: {!r}".format(h))
    return h

def rm(remote_fn, remote, timeout):
    run(["rclone", "delete", remote + remote_fn],
        check=True,
        stdin=subprocess.DEVNULL)
    # we have to wait for deleted file to go away otherwise the remove might
    # occur after the copy, which would be very bad
    @backoff(timeout)
    def _():
        try:
            logging.debug("waiting for deleted file to go away")
            md5sum(remote_fn, remote=remote)
        except Exception:
            pass
        else:
            raise ValueError("deleted file still exists")

def ls(remote_dir, remote, timeout):
    r = run(["rclone", "ls", "--include=/*", remote + remote_dir],
            check=True,
            stdin=subprocess.DEVNULL,
            stdout=subprocess.PIPE,
            universal_newlines=True)
    entries = []
    sanity_tested = False
    for line in r.stdout.split("\n"):
        line = line.lstrip()
        if not line:
            continue
        entry, = re.match(r"^ *\d+ ([^ ].*)$", line).groups()
        sys.stdout.write(shlex.quote(entry) + "\n")
        if not sanity_tested:
            try:
                md5sum(os.path.join(remote_dir, entry), remote=remote)
            except Exception:
                raise ValueError("output of 'rclone lsd' did not make sense")
            sanity_tested = True

def download(remote_fn, local_dir, remote, timeout):
    local_fn = os.path.join(local_dir, os.path.basename(remote_fn))

    # avoid unnecessary downloads
    remote_hashsum = md5sum(remote_fn, remote=remote)
    if os.path.isfile(local_fn):
        if _md5sum(local_fn) == remote_hashsum:
            return
    try_remove(local_fn)

    # download, retrying if needed
    run(["rclone", "copy", remote + remote_fn, local_dir],
        check=True,
        stdin=subprocess.DEVNULL)

    # prevent spurious successes
    if _md5sum(local_fn) != remote_hashsum:
        raise ValueError("downloaded file does not match original")

def upload(local_fn, remote_dir, remote, timeout):
    remote_fn = os.path.join(remote_dir, os.path.basename(local_fn))

    # avoid unnecessary uploads
    local_hashsum = _md5sum(local_fn)
    try:
        remote_hashsum = md5sum(remote_fn, remote=remote)
    except subprocess.CalledProcessError:
        remote_hashsum = None
    if local_hashsum == remote_hashsum:
        return
    elif remote_hashsum is not None:
        rm(remote_fn, remote=remote, timeout=timeout)

    # upload, retrying if needed
    run(["rclone", "copy", local_fn, remote + remote_dir],
        check=True,
        stdin=subprocess.DEVNULL)

    # it might take a while to get the right md5sum
    # yay for eventual consistency \o/
    @backoff(timeout)
    def _():
        logging.debug("waiting for md5sum of uploaded file to match original")
        remote_hashsum = md5sum(remote_fn, remote=remote)
        if local_hashsum != remote_hashsum:
            raise ValueError("uploaded file does not match original")

def parse_remote(remote):
    if not remote.endswith(":"):
        remote += ":"
    return remote

def main():
    log_level = int(os.environ.get("RCLONE_ACD_LOG_LEVEL", 30))
    logging.basicConfig(level=log_level, format="[%(levelname)s] %(message)s")

    p = argparse.ArgumentParser()
    p.add_argument("-t", metavar="<remote>", dest="remote", type=parse_remote)
    p.add_argument("--timeout", metavar="<secs>", type=float, default=60.0)
    sp = p.add_subparsers()

    spp = sp.add_parser("ls")
    spp.set_defaults(func=ls)
    spp.add_argument("remote_dir", metavar="<remote-dir>")

    spp = sp.add_parser("rm")
    spp.set_defaults(func=rm)
    spp.add_argument("remote_fn", metavar="<remote-fn>")

    spp = sp.add_parser("download")
    spp.set_defaults(func=download)
    spp.add_argument("remote_fn", metavar="<remote-fn>")
    spp.add_argument("local_dir", metavar="<local-dir>")

    spp = sp.add_parser("upload")
    spp.set_defaults(func=upload)
    spp.add_argument("local_fn", metavar="<local-fn>")
    spp.add_argument("remote_dir", metavar="<remote-dir>")

    p.parse_args()

    kwargs = vars(p.parse_args())
    func = kwargs.pop("func", None)
    if not func:
        p.print_usage()
        sys.exit(2)

    if not kwargs["remote"].endswith(":"):
        kwargs["remote"] += ":"
    func(**kwargs)

if __name__ == "__main__":
    main()
